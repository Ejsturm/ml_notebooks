{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "complete_path = os.getcwd()\n",
    "if 'nb' in complete_path:\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from IPython.display import clear_output\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import time\n",
    "from mlnrg.utils.logger import log\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import pairwise_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "from mlnrg.utils.mpl_at_utils import MPLAdjutant\n",
    "from mlnrg.loader import NRGData\n",
    "from mlnrg.utils import defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlnrg.utils import analysis_tools as at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 erica  staff   1.0G Sep 12 18:45 results/DC-KRR/kondo_full_alpha0.01_gamma1_subsets8.pkl\r\n",
      "-rw-r--r--  1 erica  staff   1.0G Sep 12 23:04 results/DC-KRR/kondo_full_alpha0_gamma1_subsets8.pkl\r\n",
      "-rw-r--r--  1 erica  staff   1.0G Sep 16 22:22 results/DC-KRR/kondo_full_alpha0.01_gamma0.01_subsets8.pkl\r\n",
      "-rw-r--r--  1 erica  staff   1.0G Sep 20 23:51 results/DC-KRR/kondo_full_alpha0_gamma0.01_subsets8.pkl\r\n",
      "-rw-r--r--  1 erica  staff   169M Sep 21 18:39 results/DC-KRR/KRR_kondo_fps_alpha0_gamma1_subset1_comparison.pkl\r\n",
      "-rw-r--r--  1 erica  staff    46M Oct  1 14:23 results/DC-KRR/FINAL_kondo_full_alpha0_gamma1_subsets8.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lthr results/DC-KRR/*kondo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['set', 'sampling', 'tr_set_size', 'number_subsets', 'val_set_size', 'trained_weights', 'fit_time', 'sorted_errors', 'costs'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = open('results/DC-KRR/kondo_full_alpha0_gamma1_subsets8.pkl', 'rb')\n",
    "results = pickle.load(file_name)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['set'])\n",
    "print(results['sampling'])\n",
    "print(results['tr_set_size'])\n",
    "print(results['number_subsets'])\n",
    "set_size = float(results['tr_set_size'])/float(results['number_subsets'])\n",
    "print(set_size)\n",
    "print(results['fit_time'])\n",
    "print(results['costs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tr_score = np.mean(np.array(results['costs'])[:,0])\n",
    "avg_val_score = np.mean(np.array(results['costs'][:,1]))\n",
    "\n",
    "log.info(\"\\nThe average training r^2 score:\\t\\t%.5g\\nThe average validation r^2 score:\\t%.5g\"\n",
    "        %(avg_tr_score, avg_val_score)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_error_array = np.array(results['sorted_errors'])\n",
    "raw_val_errors = validation_error_array[:,3]\n",
    "\n",
    "mean_MAE_val = np.mean(raw_val_errors)\n",
    "std_MAE_val  = np.std(raw_val_errors)\n",
    "\n",
    "print(f\"Avg validation err: %.5f +/- %.5f\" % (mean_MAE_val, std_MAE_val))\n",
    "print(f\"log10 Avg validation err: %.5f +/- %.5f\" % (np.log10(mean_MAE_val), np.log10(std_MAE_val)))\n",
    "print(f\"log10 validation median: %.5f\" % np.log10(np.median(raw_val_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors = []\n",
    "for i  in range(0, len(raw_val_errors)):\n",
    "    validation_errors.append(np.log10(raw_val_errors[i]))\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "y_Height = 0.05 * len(validation_errors)\n",
    "mean = np.log10(np.mean(raw_val_errors))\n",
    "median = np.log10(np.median(raw_val_errors))\n",
    "\n",
    "plt.hist(validation_errors, bins=60, color='k')\n",
    "for ii in range(1, 10):\n",
    "    x = np.percentile(validation_errors, ii*10)\n",
    "    plt.plot((x, x), (0, y_Height), color='r', label=\"Deciles\" if ii == 1 else None)\n",
    "plt.plot((mean, mean), (0, y_Height), color='orange', label=f\"Mean: {mean:.05g}\")\n",
    "plt.plot((median, median), (0, y_Height), color='b', label=f\"Median: {median:.05g}\")\n",
    "\n",
    "plt.title(\"Kondo Validation Trials KRR MAE\")\n",
    "plt.xlabel(\"$log_{10}(\\mathrm{MAE})$\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "plt.legend(loc=\"upper left\", frameon=False)\n",
    "\n",
    "#plt.savefig(\"Hist_anderson_fps_a\" + str(alpha) + \"_g\" + str(gamma) +\"_errors.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now, for the TEST set!!! Do not run until after hyperparameter tuning :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_set = pd.read_csv('data/Kondo_411267_trials_with_headers.csv')\n",
    "split_indexes = pickle.load(open(\"results/fps_files/kondo_fps.pkl\", \"rb\"))\n",
    "#original_data_set = pd.read_csv('data/Anderson_599578_trials_with_headers.csv')\n",
    "#split_indexes = pickle.load(open(\"results/fps_files/anderson_fps.pkl\", \"rb\"))\n",
    "\n",
    "training_idx = list(split_indexes[0]['train'])\n",
    "validation_idx = list(split_indexes[0]['valid'])\n",
    "test_idx = list(split_indexes[0]['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start with B: rescale with symlog after adjusting for B=0 cases.\n",
    "# m = (original_data_set[original_data_set['B'] != 0]['B']).abs().min()\n",
    "# original_data_set.loc[list((original_data_set[original_data_set['B'] == 0]).index), 'B'] = m/10\n",
    "\n",
    "# sign_B = np.sign(original_data_set['B'])\n",
    "# original_data_set.loc[:, 'B'] = sign_B * np.log10(np.abs(original_data_set.loc[:, 'B']))\n",
    "# #data_set.rename(columns={'B': 'symlog10 B'}, inplace=True)\n",
    "\n",
    "# # Now do T: rescale with regular log after adjusting for T=0 cases.\n",
    "# m = (original_data_set[original_data_set['T'] != 0]['T']).abs().min()\n",
    "# original_data_set.loc[list((original_data_set[original_data_set['T'] == 0]).index), 'T'] = m/10\n",
    "# original_data_set.loc[:, 'T'] = np.log10(original_data_set.loc[:, 'T'])\n",
    "# #data_set.rename(columns={'T': 'log10 T'}, inplace=True)\n",
    "\n",
    "# # Now do Gamma: recale with regular log.\n",
    "# original_data_set.loc[:, 'Gamma'] = np.log10(original_data_set.loc[:, 'Gamma'])\n",
    "# #data_set.rename(columns={'Gamma': 'log10 Gamma'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_tr_features = (original_data_set.loc[training_idx[:],'U':'T']).to_numpy()\n",
    "tr_targets = (original_data_set.iloc[training_idx[:], 8:]).to_numpy()\n",
    "number_subsets = results['number_subsets']\n",
    "remainder_trials = len(unscaled_tr_features) % number_subsets\n",
    "log.info(\"\\nTo attain the desired number of subsets, %d trials had to be removed from training.\" \n",
    "         % remainder_trials\n",
    "        )\n",
    "\n",
    "if (remainder_trials >= len(unscaled_tr_features)*0.001):\n",
    "    log.warn(\"The number of subsets requested will require the removal of %d, \"\\\n",
    "             \"more than 1/1000 of the available training data.\" \n",
    "            )\n",
    "if (remainder_trials != 0):    \n",
    "    unscaled_tr_features = unscaled_tr_features[:-1*remainder_trials]\n",
    "    tr_targets = tr_targets[:-1*remainder_trials]\n",
    "    \n",
    "subset_size = len(unscaled_tr_features)/number_subsets # (Will be 5K if using all default values.)\n",
    "\n",
    "all_starting_trials = len(unscaled_tr_features)\n",
    "log.info(\"\\nOriginal number of training trials:\\t%d\\nRemaining number of training trials:\\t%d\"\\\n",
    "        \"\\nRemoved trials:\\t\\t%d (%.5g%% of the total trials)\\nNumber of subsets:\\t%d\\n\"\\\n",
    "        \"Trials per subset:\\t%6.1f\"\n",
    "         % (all_starting_trials, len(unscaled_tr_features), remainder_trials, \n",
    "            (100*remainder_trials/all_starting_trials), number_subsets, subset_size) \n",
    "        )\n",
    "\n",
    "subset_size = int(subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_TEST_features = (original_data_set.loc[test_idx,'U':'T']).to_numpy()\n",
    "TEST_targets = (original_data_set.iloc[test_idx[:], 8:]).to_numpy()\n",
    "TEST_indexes = (original_data_set.loc[test_idx,'idx']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_scaling = unscaled_tr_features.mean(axis=0)\n",
    "std_scaling = unscaled_tr_features.std(axis=0)\n",
    "\n",
    "tr_features = (unscaled_tr_features - mu_scaling) /std_scaling\n",
    "TEST_features = (unscaled_TEST_features - mu_scaling) / std_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "gamma = 1\n",
    "\n",
    "trained_weights = np.array(results['trained_weights'])\n",
    "all_tr_subset_features = np.array_split(tr_features, number_subsets) \n",
    "all_tr_subset_targets = np.array_split(tr_targets, number_subsets)\n",
    "all_alpha_weights = results['trained_weights']\n",
    "\n",
    "sum_predictions = np.zeros([1, TEST_targets.shape[1]]) \n",
    "TEST_costs = np.empty([number_subsets, 1])\n",
    "\n",
    "time_start = time.time()\n",
    "for s in range(0, number_subsets):\n",
    "    t0 = time.time()\n",
    "    iter_tr_features = all_tr_subset_features[s]\n",
    "    iter_tr_weight = np.reshape(all_alpha_weights[s], [int(set_size), TEST_targets.shape[1]])\n",
    "    \n",
    "    iter_kernel_of_TEST_and_tr = pairwise_kernels(TEST_features, iter_tr_features, \n",
    "                                                  metric='laplacian', \n",
    "                                                  alpha=alpha,\n",
    "                                                  gamma=gamma, \n",
    "                                                  filter_params=True\n",
    "                                                 )\n",
    "    \n",
    "    iter_prediction = np.dot(iter_kernel_of_TEST_and_tr, iter_tr_weight)\n",
    "    \n",
    "    u_value = ((TEST_targets - iter_prediction)**2).sum()\n",
    "    v_value = ((TEST_targets - TEST_targets.mean())**2).sum()\n",
    "    iter_TEST_cost = 1 - (u_value/v_value)\n",
    "    TEST_costs[s,0] = iter_TEST_cost\n",
    "    \n",
    "    sum_predictions = np.add(sum_predictions, iter_prediction)\n",
    "    iter_time = time.time() - t0\n",
    "    \n",
    "    print(\"Iteration %d/%d compelte in: %.3g seconds\\nTesting Cost = %.5g\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\" \n",
    "          % (s+1, number_subsets, iter_time, iter_TEST_cost)\n",
    "         )\n",
    "    \n",
    "#--------------------------------\n",
    "# THIS IS THE FINAL PREDICTION!!!\n",
    "#--------------------------------\n",
    "averaged_TEST_predictions = sum_predictions / number_subsets\n",
    "\n",
    "fit_time = time.time() - time_start\n",
    "log.info(\"\\nAll %d/%d subsets with %d trials/subset tested and averaged.\\n %d trials in test set. Total time: %.5g seconds\" \n",
    "         % (s+1, number_subsets, subset_size, len(TEST_targets), fit_time)\n",
    "        )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Result = namedtuple('Result', ['pred', 'target', 'feature', 'meta', 'name', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_TEST_errors = np.mean(np.abs(TEST_targets - averaged_TEST_predictions), axis=1)\n",
    "sorted_TEST_errors = []\n",
    "all_test_results = []\n",
    "for ii in range(len(raw_TEST_errors)):\n",
    "  sorted_TEST_errors.append([ii, TEST_targets[ii], averaged_TEST_predictions[ii], raw_TEST_errors[ii]])\n",
    "  all_test_results.append(Result(pred=averaged_TEST_predictions[ii].tolist(),\n",
    "                                 target=TEST_targets[ii].tolist(), \n",
    "                                 feature=TEST_features[ii].tolist(), \n",
    "                                 meta=None, \n",
    "                                 name=int(TEST_indexes[ii]), \n",
    "                                 mae=float(raw_TEST_errors[ii])\n",
    "                                )\n",
    "                         )\n",
    "\n",
    "sorted_TEST_errors.sort(key=lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "y_Height = 0.05 * len(raw_TEST_errors)\n",
    "mean = np.log10(np.mean(raw_TEST_errors))\n",
    "median = np.log10(np.median(raw_TEST_errors))\n",
    "\n",
    "plt.hist(np.log10(raw_TEST_errors), bins=60, color='k')\n",
    "for ii in range(1, 10):\n",
    "    x = np.percentile(np.log10(raw_TEST_errors), ii*10)\n",
    "    plt.plot((x, x), (0, y_Height), color='r', label=\"Deciles\" if ii == 1 else None)\n",
    "plt.plot((mean, mean), (0, y_Height), color='orange', label=f\"Mean: {mean:.05g}\")\n",
    "plt.plot((median, median), (0, y_Height), color='b', label=f\"Median: {median:.05g}\")\n",
    "\n",
    "plt.title(\"FPS Kondo Test Trials KRR MAE\")\n",
    "plt.xlabel(\"$log_{10}(\\mathrm{MAE})$\")\n",
    "plt.ylabel(\"Occurances\")\n",
    "plt.legend(loc=\"upper left\", frameon=False)\n",
    "\n",
    "#plt.savefig(\"Hist_anderson_fps_a\" + str(alpha) + \"_g\" + str(gamma) +\"_errors.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All test r^2 values:\")\n",
    "print(TEST_costs)\n",
    "print(\"\\nAveraged test r^2 value: %.8f\\n\" % np.mean(TEST_costs))\n",
    "\n",
    "mean_MAE_TEST_set = np.mean(raw_TEST_errors)\n",
    "std_MAE_TEST_set = np.std(raw_TEST_errors)\n",
    "median_MAE_TEST_set = np.median(raw_TEST_errors)\n",
    "print(f\"Avg  err: %.5f +/- %.5f\" % (mean_MAE_TEST_set, std_MAE_TEST_set))\n",
    "\n",
    "print(f\"Log10 mean MAE:\\t %.5f +/- %.5f\" % (np.log10(mean_MAE_TEST_set), np.log10(std_MAE_TEST_set)))\n",
    "print(f\"Log10 median MAE:\\t %.5f\" % np.log10(median_MAE_TEST_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(TEST_costs)):\n",
    "    print(i)\n",
    "    print(np.array([results['costs'][i,1]]))\n",
    "    print(TEST_costs[i])\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "\n",
    "plt.scatter(np.arange(1,number_subsets+1), np.array(results['costs'][:,1]), \n",
    "            color=\"black\", s=10,\n",
    "            label=\"Validation\")\n",
    "plt.scatter(np.arange(1,number_subsets+1), TEST_costs, \n",
    "            facecolors='none', edgecolors='red', s=10,\n",
    "            label=\"Test\")  \n",
    "\n",
    "plt.xticks(np.arange(1,8.9), fontsize=8)\n",
    "plt.yticks(np.arange(0.5,1.1,.1), fontsize=8)\n",
    "plt.xlim([0.3,8.65])\n",
    "plt.ylim([0.45, 1.025])\n",
    "plt.legend(loc=\"lower left\", prop={'size': 6}, frameon=False)\n",
    "plt.xlabel(\"Subset $s$\", fontsize=8)\n",
    "plt.ylabel(r\"$r^2$ score\",fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save relevant info and pickle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all r^2 scores into a single dataframe. \n",
    "all_r2_scores = pd.DataFrame(\n",
    "    {\n",
    "        'train': results['costs'][:,0],\n",
    "        'valid': results['costs'][:,1],\n",
    "        'test': TEST_costs[:,0]\n",
    "    }\n",
    ")\n",
    "print(all_r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up information for pickle in a dictionary because it's convenient!\n",
    "\n",
    "dckrr_pickle_info = {\n",
    "    \"dataset\": \"kondo\",\n",
    "    \"N_total\": 411267,\n",
    "    \"S_subsets\": number_subsets,\n",
    "    \"n_trials_per_subset\": set_size,\n",
    "    \"ker_params\": {\"kernel\": 'laplacian', \"alpha\": alpha, \"gamma\": gamma},\n",
    "    \"sampler\": \"fps\",\n",
    "    \"normalize_features_via_train\": True,\n",
    "    \"scale_features_via_train\": False,\n",
    "    \"r2_scores\": all_r2_scores,\n",
    "    \"RESULTS\": all_test_results \n",
    "}\n",
    "\n",
    "\n",
    "pickle.dump(dckrr_pickle_info, open(\"results/DC-KRR/FINAL_kondo_full_alpha0_gamma1_subsets8.pkl\", \"wb\" ))\n",
    "\n",
    "\n",
    "# dckrr_info = {\n",
    "#     \"set\": \"anderson\",\n",
    "#     \"sampling\": \"fps\",\n",
    "#     \"alpha\": alpha,\n",
    "#     \"gamma\": gamma,\n",
    "#     \"tr_set_size\": len(tr_features),\n",
    "#     \"number_subsets\": number_subsets,\n",
    "#     \"val_set_size\": len(val_features),\n",
    "#     \"trained_weights\": alpha_weights,\n",
    "#     \"fit_time\": fit_time,\n",
    "#     \"sorted_errors\": sorted_errors,\n",
    "#     \"costs\": iter_costs\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# {'batch_sizes': [1000, 1000, 5120],\n",
    "#  'dataset': 'anderson',\n",
    "#  'dataset_info': {'ntestval': 24000,\n",
    "#   'ntotal': 599578,\n",
    "#   'path': '/hpcgpfs01/scratch/mcarbone/mlnrg/Anderson_599578_trials_with_headers.csv'},\n",
    "#  'epochs': 1000,\n",
    "#  'grid_path': '/hpcgpfs01/scratch/mcarbone/mlnrg/Omega_grid_values.csv',\n",
    "#  'idx_dir': '.idx',\n",
    "#  'loss': 'l1',\n",
    "#  'net_params': {'dropout': 0.0, 'hidden_size': 100, 'n_hidden_layers': 3},\n",
    "#  'protocol': 'standardMLP',\n",
    "#  'sampler': 'fps',\n",
    "#  'sampler_type': None,\n",
    "#  'scale_features_via_train': True,\n",
    "#  'scale_properties': True,\n",
    "#  'target_dir': '/sdcc/u/mcarbone/mlnrg/results/downsampling_check_rerun/004',\n",
    "#  'train_up_to': 50000,\n",
    "#  'transform': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_map = {\n",
    "    'kondo': 'data/Kondo_411267_trials_with_headers.csv',\n",
    "    'anderson': 'data/Anderson_599578_trials_with_headers.csv',\n",
    "    'grid': 'data/Omega_grid_values.csv'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class_no_scale = NRGData()\n",
    "data_class_no_scale.load(path=dataset_map['anderson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results, test_unscaled_energies = at.set_up_df(all_test_results, data_class_no_scale, \"anderson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles, mean, median = at.plot_err_histogram(test_results['err'], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.plot_param_best_and_worst_dist(test_results, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.plot_best_and_worst_SPE_control(test_results, test_unscaled_energies, \"anderson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.plot_percentile(all_test_results, data_class_no_scale, percentile=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.plot_single_prediction(all_test_results, data_class_no_scale, np.array(data_class_no_scale.grid), 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at.plot_single_trial(data_class_no_scale, np.array(data_class_no_scale.grid), 91412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(seed=42)\n",
    "test_names = (original_data_set.loc[test_idx[:],'idx']).to_numpy()\n",
    "\n",
    "selections = np.random.choice(test_names, size=25, replace=False)\n",
    "print(selections)\n",
    "at.plot_random_25(all_test_results, data_class_no_scale, np.array(data_class_no_scale.grid), selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in zip(np.arange(1,number_subsets+1), np.array(results['costs'][:,1])):\n",
    "    label1 = \"{:.4f}\".format(y)\n",
    "\n",
    "    plt.annotate(label1, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,-8), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0\n",
    "                )\n",
    "for xx,yy in zip(np.arange(1,10), np.array(TEST_costs.flatten())[:10]):\n",
    "    label2 = \"{:.4f}\".format(yy)\n",
    "\n",
    "    plt.annotate(label2, # this is the text\n",
    "                 (xx,yy), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,5), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0,\n",
    "                 color=\"red\"\n",
    "                )  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################### BEGIN NOTATION  ############################\n",
    "for x,y in zip(np.array([1,2,3,4,5,6,8,9]), np.array(results['costs'][[0,1,2,3,4,5,7,8,9],1])):\n",
    "    label1 = \"{:.4f}\".format(y)\n",
    "\n",
    "    plt.annotate(label1, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,-8), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0\n",
    "                )\n",
    "for xx,yy in zip(np.array([1,2,3,4,5,6,8,9]), np.array(TEST_costs.flatten())[[0,1,2,3,4,5,7,8]]):\n",
    "    label2 = \"{:.4f}\".format(yy)\n",
    "\n",
    "    plt.annotate(label2, # this is the text\n",
    "                 (xx,yy), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,5), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0,\n",
    "                 color=\"red\"\n",
    "                )    \n",
    "############################### POINTS 10,11 ANDERSON ############################    \n",
    "for x,y in zip(np.arange(9,number_subsets-1), np.array(results['costs'][9:11,1])):\n",
    "    label1 = \"{:.4f}\".format(y)\n",
    "\n",
    "    plt.annotate(label1, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(10,5), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0\n",
    "                )\n",
    "for xx,yy in zip(np.arange(9, number_subsets-1), np.array(TEST_costs.flatten())[9:11]):\n",
    "    label2 = \"{:.4f}\".format(yy)\n",
    "\n",
    "    plt.annotate(label2, # this is the text\n",
    "                 (xx,yy), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(10,-8), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0,\n",
    "                 color=\"red\"\n",
    "                )  \n",
    "############################### LAST POINT ANDERSON ############################    \n",
    "for x,y in zip(np.array([7]), np.array([results['costs'][6,1]])):\n",
    "    label1 = \"{:.4f}\".format(y)\n",
    "\n",
    "    plt.annotate(label1, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,5), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0\n",
    "                )\n",
    "for xx,yy in zip(np.array([7]), TEST_costs[6]):\n",
    "    label2 = \"{:.4f}\".format(yy)\n",
    "\n",
    "    plt.annotate(label2, # this is the text\n",
    "                 (xx,yy), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,-8), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0,\n",
    "                 color=\"red\"\n",
    "                )  \n",
    "\n",
    "for x,y in zip(np.array([12]), np.array([results['costs'][11,1]])):\n",
    "    label1 = \"{:.4f}\".format(y)\n",
    "\n",
    "    plt.annotate(label1, # this is the text\n",
    "                 (x,y), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,-8), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0\n",
    "                )\n",
    "for xx,yy in zip(np.array([12]), TEST_costs[11]):\n",
    "    label2 = \"{:.4f}\".format(yy)\n",
    "\n",
    "    plt.annotate(label2, # this is the text\n",
    "                 (xx,yy), # this is the point to label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-8,5), # distance from text to points (x,y)\n",
    "                 ha='left', # horizontal alignment can be left, right or center\n",
    "                 fontsize=4.5,\n",
    "                 rotation=0,\n",
    "                 color=\"red\"\n",
    "                )   \n",
    "###########################################################################  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
